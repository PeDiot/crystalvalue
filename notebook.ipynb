{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "iTsKaxLPY37t",
      "metadata": {
        "id": "iTsKaxLPY37t"
      },
      "source": [
        "# Crystalvalue Demo: Predictive Customer LifeTime Value for a Retail Store\n",
        "\n",
        "Crystalvalue is a best practice comprehensive solution for running predictive LTV solutions leveraging Google Cloud Vertex AI. \n",
        "\n",
        "This demo runs the Crystalvalue python library in a notebook, from feature engineering to scheduling predictions. It uses the [Online Retail II data set from Kaggle](https://www.kaggle.com/mashlyn/online-retail-ii-uci) which contains transactions for a UK retail store between 2009 and 2011. Enable the [Vertex API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,storage-component.googleapis.com) for this demo to run.\n",
        "\n",
        "This notebook assumes that it is being run from within a [Google Cloud Platform AI Notebook](https://console.cloud.google.com/vertex-ai/notebooks/list/instances) with a Compute Engine default service account (the default setting when an AI Notebook is created) and TensorFlow backend. Ensure that the [Compute Engine default service account API](https://console.cloud.google.com/flows/enableapi?apiid=compute.googleapis.com) is enabled. When running it on your own data, we recommend [setting up your own service account](https://cloud.google.com/vertex-ai/docs/pipelines/configure-project).\n",
        "\n",
        "If you would like to share feedback about Crystalvalue, please email crystalvalue@google.com."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1_M6mv5_Al18",
      "metadata": {
        "id": "1_M6mv5_Al18"
      },
      "source": [
        "# Clone the Crystalvalue codebase"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hnySWWD2DbJ8",
      "metadata": {
        "id": "hnySWWD2DbJ8"
      },
      "source": [
        "Start by cloning the Crystalvalue codebase and running a demo notebook from the root directory. To run Crystalvalue on your own data, simply change the parameters to it works on your data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a6QSkrxSFsCB",
      "metadata": {
        "id": "a6QSkrxSFsCB"
      },
      "source": [
        "```git clone https://github.com/google/crystalvalue```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef1faf60",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0783cc9e",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src import crystalvalue"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "672173f7",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "fe3f1fa0",
      "metadata": {},
      "outputs": [],
      "source": [
        "CREDENTIALS_PATH = \"secrets/gcp_credentials.json\"\n",
        "DATA_PATH = \"data/cleaned.csv\"\n",
        "PARAMETERS_FILENAME = \"data/crystalvalue_parameters.json\"\n",
        "\n",
        "GCP_PROJECT_ID = \"pltv-457408\"\n",
        "GCP_LOCATION = \"europe-west9\"\n",
        "GCP_DATASET_ID = \"crystalvalue\"\n",
        "GCP_TABLE_ID_TRAIN = \"train\"\n",
        "GCP_TABLE_ID_PREDICT = \"predict\"\n",
        "\n",
        "CUSTOMER_ID_COLUMN = \"customer_id\"\n",
        "DATE_COLUMN = \"date\"\n",
        "VALUE_COLUMN = \"value\"\n",
        "IGNORE_COLUMNS = [\"order_number\", \"days_to_next_order\"] # we ignore days_to_next_order because it is calculated by crystalvalue\n",
        "\n",
        "LOOKBACK_DAYS = 365\n",
        "LOOKAHEAD_DAYS = 365\n",
        "\n",
        "TEST_YEAR = 2024\n",
        "TEST_MONTH = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69c2677a",
      "metadata": {},
      "source": [
        "# Load & preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2a8daf94",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>date</th>\n",
              "      <th>order_number</th>\n",
              "      <th>shipping_address_zip</th>\n",
              "      <th>value</th>\n",
              "      <th>value_cat1</th>\n",
              "      <th>value_cat2</th>\n",
              "      <th>value_cat3</th>\n",
              "      <th>value_cat4</th>\n",
              "      <th>value_cat5</th>\n",
              "      <th>value_cat6</th>\n",
              "      <th>value_uncategorized</th>\n",
              "      <th>order_index</th>\n",
              "      <th>days_to_next_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>761</td>\n",
              "      <td>93320</td>\n",
              "      <td>48.23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.65</td>\n",
              "      <td>2.34</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.24</td>\n",
              "      <td>4</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>552</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>762</td>\n",
              "      <td>17100</td>\n",
              "      <td>55.91</td>\n",
              "      <td>1.37</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.01</td>\n",
              "      <td>5.24</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>44.29</td>\n",
              "      <td>1</td>\n",
              "      <td>84.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>487</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>763</td>\n",
              "      <td>7320</td>\n",
              "      <td>36.12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>36.12</td>\n",
              "      <td>2</td>\n",
              "      <td>334.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>553</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>764</td>\n",
              "      <td>13360</td>\n",
              "      <td>11.08</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.33</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8.75</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>277</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>765</td>\n",
              "      <td>45000</td>\n",
              "      <td>33.95</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.67</td>\n",
              "      <td>5.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>26.68</td>\n",
              "      <td>3</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_id        date  order_number shipping_address_zip  value  \\\n",
              "0          328  2022-06-01           761                93320  48.23   \n",
              "1          552  2022-06-01           762                17100  55.91   \n",
              "2          487  2022-06-01           763                 7320  36.12   \n",
              "3          553  2022-06-01           764                13360  11.08   \n",
              "4          277  2022-06-01           765                45000  33.95   \n",
              "\n",
              "   value_cat1  value_cat2  value_cat3  value_cat4  value_cat5  value_cat6  \\\n",
              "0         NaN        1.65        2.34         NaN         NaN         NaN   \n",
              "1        1.37         NaN        5.01        5.24         NaN         NaN   \n",
              "2         NaN         NaN         NaN         NaN         NaN         NaN   \n",
              "3         NaN         NaN        2.33         NaN         NaN         NaN   \n",
              "4         NaN         NaN         NaN        1.67         5.6         NaN   \n",
              "\n",
              "   value_uncategorized  order_index  days_to_next_order  \n",
              "0                44.24            4                40.0  \n",
              "1                44.29            1                84.0  \n",
              "2                36.12            2               334.0  \n",
              "3                 8.75            1                 NaN  \n",
              "4                26.68            3                23.0  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the data and rename the columns to be BiqQuery friendly (no spaces).\n",
        "data = pd.read_csv(DATA_PATH)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a3b9001a",
      "metadata": {},
      "outputs": [],
      "source": [
        "value_cols = [f\"value_cat{i}\" for i in range(1, 7)]\n",
        "value_cols.append(\"value_uncategorized\")\n",
        "\n",
        "# replace na with 0 since na means category product is not ordered\n",
        "data[value_cols] = data[value_cols].fillna(0)\n",
        "\n",
        "# create value column as sum of per category value\n",
        "data[\"value\"] = data[value_cols].sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8dfd12f5",
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert order_index to category\n",
        "data[\"order_index\"] = data[\"order_index\"].astype(\"string\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "42f9f875",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>date</th>\n",
              "      <th>order_number</th>\n",
              "      <th>shipping_address_zip</th>\n",
              "      <th>value</th>\n",
              "      <th>value_cat1</th>\n",
              "      <th>value_cat2</th>\n",
              "      <th>value_cat3</th>\n",
              "      <th>value_cat4</th>\n",
              "      <th>value_cat5</th>\n",
              "      <th>value_cat6</th>\n",
              "      <th>value_uncategorized</th>\n",
              "      <th>order_index</th>\n",
              "      <th>days_to_next_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>328</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>761</td>\n",
              "      <td>93320</td>\n",
              "      <td>48.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.65</td>\n",
              "      <td>2.34</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.24</td>\n",
              "      <td>4</td>\n",
              "      <td>40.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>552</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>762</td>\n",
              "      <td>17100</td>\n",
              "      <td>55.91</td>\n",
              "      <td>1.37</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.01</td>\n",
              "      <td>5.24</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>44.29</td>\n",
              "      <td>1</td>\n",
              "      <td>84.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>487</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>763</td>\n",
              "      <td>7320</td>\n",
              "      <td>36.12</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.12</td>\n",
              "      <td>2</td>\n",
              "      <td>334.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>553</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>764</td>\n",
              "      <td>13360</td>\n",
              "      <td>11.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8.75</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>277</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>765</td>\n",
              "      <td>45000</td>\n",
              "      <td>33.95</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.67</td>\n",
              "      <td>5.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.68</td>\n",
              "      <td>3</td>\n",
              "      <td>23.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_id        date  order_number shipping_address_zip  value  \\\n",
              "0          328  2022-06-01           761                93320  48.23   \n",
              "1          552  2022-06-01           762                17100  55.91   \n",
              "2          487  2022-06-01           763                 7320  36.12   \n",
              "3          553  2022-06-01           764                13360  11.08   \n",
              "4          277  2022-06-01           765                45000  33.95   \n",
              "\n",
              "   value_cat1  value_cat2  value_cat3  value_cat4  value_cat5  value_cat6  \\\n",
              "0        0.00        1.65        2.34        0.00         0.0         0.0   \n",
              "1        1.37        0.00        5.01        5.24         0.0         0.0   \n",
              "2        0.00        0.00        0.00        0.00         0.0         0.0   \n",
              "3        0.00        0.00        2.33        0.00         0.0         0.0   \n",
              "4        0.00        0.00        0.00        1.67         5.6         0.0   \n",
              "\n",
              "   value_uncategorized order_index  days_to_next_order  \n",
              "0                44.24           4                40.0  \n",
              "1                44.29           1                84.0  \n",
              "2                36.12           2               334.0  \n",
              "3                 8.75           1                 NaN  \n",
              "4                26.68           3                23.0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "eb74e218",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53505 entries, 0 to 53504\n",
            "Data columns (total 14 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   customer_id           53505 non-null  int64  \n",
            " 1   date                  53505 non-null  object \n",
            " 2   order_number          53505 non-null  int64  \n",
            " 3   shipping_address_zip  53220 non-null  object \n",
            " 4   value                 53505 non-null  float64\n",
            " 5   value_cat1            53505 non-null  float64\n",
            " 6   value_cat2            53505 non-null  float64\n",
            " 7   value_cat3            53505 non-null  float64\n",
            " 8   value_cat4            53505 non-null  float64\n",
            " 9   value_cat5            53505 non-null  float64\n",
            " 10  value_cat6            53505 non-null  float64\n",
            " 11  value_uncategorized   53505 non-null  float64\n",
            " 12  order_index           53505 non-null  string \n",
            " 13  days_to_next_order    27592 non-null  float64\n",
            "dtypes: float64(9), int64(2), object(2), string(1)\n",
            "memory usage: 5.7+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7ec01b7",
      "metadata": {},
      "source": [
        "# Train/Test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ac08b1d7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((51359, 14), (2146, 14))"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "first_orders = data.groupby(\"customer_id\")[\"date\"].min().reset_index()\n",
        "first_orders[\"date\"] = pd.to_datetime(first_orders[\"date\"])\n",
        "\n",
        "predict_mask = (first_orders[\"date\"].dt.year == TEST_YEAR) & (first_orders[\"date\"].dt.month == TEST_MONTH)\n",
        "predict_customer_ids = first_orders[predict_mask][\"customer_id\"].tolist()\n",
        "\n",
        "predict_data = data[data[\"customer_id\"].isin(predict_customer_ids)]\\\n",
        "    .sort_values([\"customer_id\", \"date\"], ascending=[True, True])\\\n",
        "    .reset_index(drop=True)\n",
        "\n",
        "train_data = data[~data[\"customer_id\"].isin(predict_customer_ids)]\\\n",
        "    .sort_values([\"customer_id\", \"date\"], ascending=[True, True])\\\n",
        "    .reset_index(drop=True)\n",
        "\n",
        "train_data.shape, predict_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e1bcf6cd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>customer_id</th>\n",
              "      <th>date</th>\n",
              "      <th>order_number</th>\n",
              "      <th>shipping_address_zip</th>\n",
              "      <th>value</th>\n",
              "      <th>value_cat1</th>\n",
              "      <th>value_cat2</th>\n",
              "      <th>value_cat3</th>\n",
              "      <th>value_cat4</th>\n",
              "      <th>value_cat5</th>\n",
              "      <th>value_cat6</th>\n",
              "      <th>value_uncategorized</th>\n",
              "      <th>order_index</th>\n",
              "      <th>days_to_next_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>338</td>\n",
              "      <td>2024-03-29</td>\n",
              "      <td>26696</td>\n",
              "      <td>57920</td>\n",
              "      <td>65.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>39.16</td>\n",
              "      <td>14.86</td>\n",
              "      <td>7.63</td>\n",
              "      <td>3.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>351</td>\n",
              "      <td>2024-03-22</td>\n",
              "      <td>26059</td>\n",
              "      <td>93160</td>\n",
              "      <td>40.25</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.75</td>\n",
              "      <td>38.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13788</td>\n",
              "      <td>2024-03-01</td>\n",
              "      <td>24901</td>\n",
              "      <td>57070</td>\n",
              "      <td>39.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>39.75</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13789</td>\n",
              "      <td>2024-03-01</td>\n",
              "      <td>24905</td>\n",
              "      <td>33360</td>\n",
              "      <td>63.50</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.05</td>\n",
              "      <td>17.78</td>\n",
              "      <td>13.07</td>\n",
              "      <td>11.60</td>\n",
              "      <td>0.00</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13790</td>\n",
              "      <td>2024-03-01</td>\n",
              "      <td>24907</td>\n",
              "      <td>24130</td>\n",
              "      <td>39.46</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>34.36</td>\n",
              "      <td>0.00</td>\n",
              "      <td>5.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>51.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>13790</td>\n",
              "      <td>2024-04-21</td>\n",
              "      <td>28388</td>\n",
              "      <td>24130</td>\n",
              "      <td>81.31</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>60.86</td>\n",
              "      <td>20.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>13790</td>\n",
              "      <td>2024-07-12</td>\n",
              "      <td>33488</td>\n",
              "      <td>13960</td>\n",
              "      <td>62.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>62.42</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>108.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>13790</td>\n",
              "      <td>2024-10-28</td>\n",
              "      <td>40052</td>\n",
              "      <td>24130</td>\n",
              "      <td>48.81</td>\n",
              "      <td>4.12</td>\n",
              "      <td>2.77</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>41.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "      <td>38.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>13790</td>\n",
              "      <td>2024-12-05</td>\n",
              "      <td>43129</td>\n",
              "      <td>24130</td>\n",
              "      <td>52.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>23.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>29.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>13791</td>\n",
              "      <td>2024-03-01</td>\n",
              "      <td>24910</td>\n",
              "      <td>93270</td>\n",
              "      <td>15.31</td>\n",
              "      <td>12.39</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.70</td>\n",
              "      <td>1.22</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   customer_id        date  order_number shipping_address_zip  value  \\\n",
              "0          338  2024-03-29         26696                57920  65.00   \n",
              "1          351  2024-03-22         26059                93160  40.25   \n",
              "2        13788  2024-03-01         24901                57070  39.75   \n",
              "3        13789  2024-03-01         24905                33360  63.50   \n",
              "4        13790  2024-03-01         24907                24130  39.46   \n",
              "5        13790  2024-04-21         28388                24130  81.31   \n",
              "6        13790  2024-07-12         33488                13960  62.42   \n",
              "7        13790  2024-10-28         40052                24130  48.81   \n",
              "8        13790  2024-12-05         43129                24130  52.39   \n",
              "9        13791  2024-03-01         24910                93270  15.31   \n",
              "\n",
              "   value_cat1  value_cat2  value_cat3  value_cat4  value_cat5  value_cat6  \\\n",
              "0        0.00        0.00       39.16       14.86        7.63        3.35   \n",
              "1        0.00        0.00        1.75       38.50        0.00        0.00   \n",
              "2        0.00        0.00       39.75        0.00        0.00        0.00   \n",
              "3        0.00        6.05       17.78       13.07       11.60        0.00   \n",
              "4        0.00        0.00       34.36        0.00        5.10        0.00   \n",
              "5        0.00        0.00       60.86       20.45        0.00        0.00   \n",
              "6        0.00        0.00       62.42        0.00        0.00        0.00   \n",
              "7        4.12        2.77        0.00        0.00       41.92        0.00   \n",
              "8        0.00        0.00       23.00        0.00       29.39        0.00   \n",
              "9       12.39        0.00        0.00        1.70        1.22        0.00   \n",
              "\n",
              "   value_uncategorized order_index  days_to_next_order  \n",
              "0                  0.0           2                 NaN  \n",
              "1                  0.0           2                 NaN  \n",
              "2                  0.0           1                 NaN  \n",
              "3                 15.0           1                 NaN  \n",
              "4                  0.0           1                51.0  \n",
              "5                  0.0           2                82.0  \n",
              "6                  0.0           3               108.0  \n",
              "7                  0.0           4                38.0  \n",
              "8                  0.0           5                 NaN  \n",
              "9                  0.0           1                 NaN  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict_data.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1O4OhKV5Y37u",
      "metadata": {
        "id": "1O4OhKV5Y37u"
      },
      "source": [
        "# Initializing Crystalvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XMYviqrPHbKD",
      "metadata": {
        "id": "XMYviqrPHbKD"
      },
      "source": [
        "First create a dataset in [Bigquery](https://console.cloud.google.com/bigquery) that will be used for this analysis if you don\"t already have one. The dataset location should be in a [location that Vertex AI services are available](https://cloud.google.com/vertex-ai/docs/general/locations#available_regions). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "c2523c96",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load GCP credentials\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    filename=CREDENTIALS_PATH\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "gCVphBgXY37w",
      "metadata": {
        "id": "gCVphBgXY37w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:absl:Using Google Cloud Project: 'pltv-457408'\n",
            "INFO:absl:Using dataset_id: 'crystalvalue'\n",
            "INFO:absl:Using Google Cloud location: 'europe-west9'\n",
            "INFO:absl:Using customer id column in input table: 'customer_id'\n",
            "INFO:absl:Using date column in input table: 'date'\n",
            "INFO:absl:Using value column in input table: 'value'\n",
            "INFO:absl:Using days_lookback for feature calculation: 365\n",
            "INFO:absl:Using days_lookahead for value prediction: 365\n",
            "INFO:absl:Using trigger_event_date_column for value prediction: None\n",
            "INFO:absl:Parameters writen to file: 'crystalvalue_parameters.json'\n"
          ]
        }
      ],
      "source": [
        "# Initiate the CrystalValue class with the relevant parameters.\n",
        "pipeline = crystalvalue.CrystalValue(\n",
        "  project_id=GCP_PROJECT_ID,  # The GCP project id.\n",
        "  dataset_id=GCP_DATASET_ID,  # The name of the pre-created dataset to work in. \n",
        "  credentials=credentials,  # The (optional) credentials to authenticate Bigquery and AIPlatform clients.\n",
        "  training_table_name=GCP_TABLE_ID_TRAIN,\n",
        "  predict_table_name=GCP_TABLE_ID_PREDICT,\n",
        "  customer_id_column=CUSTOMER_ID_COLUMN,  # The customer ID column.\n",
        "  date_column=DATE_COLUMN,  # The transaction date column.\n",
        "  value_column=VALUE_COLUMN,  #  Column to use for LTV calculation (i.e. profit or revenue).\n",
        "  days_lookback=LOOKBACK_DAYS,  #  How many days in the past to use for feature engineering.\n",
        "  days_lookahead=LOOKAHEAD_DAYS,  #  How many days in the future to use for value prediction.\n",
        "  ignore_columns=IGNORE_COLUMNS,  #  A list of columns in your input table to ignore.\n",
        "  location=GCP_LOCATION,  # This is the location of your dataset in Bigquery.\n",
        "  write_parameters=True,  #  Write parameters to local file so they can be retrieved for prediction.\n",
        "  parameters_filename=PARAMETERS_FILENAME\n",
        ")  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0qlNEnCjcL9f",
      "metadata": {
        "id": "0qlNEnCjcL9f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pierre-emmanuel/Documents/freelance/pltv/venv/lib/python3.9/site-packages/google/cloud/bigquery/_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
            "  warnings.warn(\n",
            "/Users/pierre-emmanuel/Documents/freelance/pltv/venv/lib/python3.9/site-packages/google/cloud/bigquery/_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "pipeline.load_dataframe_to_bigquery(data=train_data, bq_table_name=GCP_TABLE_ID_TRAIN)\n",
        "pipeline.load_dataframe_to_bigquery(data=predict_data, bq_table_name=GCP_TABLE_ID_PREDICT)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FHC77gHNcRDP",
      "metadata": {
        "id": "FHC77gHNcRDP"
      },
      "source": [
        "# Data Checks (Optional)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xIfjG7zNcVtx",
      "metadata": {
        "id": "xIfjG7zNcVtx"
      },
      "source": [
        "CrystalValue will run some checks on your data to check if the data is suitable for LTV modelling and raise errors if not. This will also output a new BigQuery table in your dataset called `crystalvalue_data_statistics` with key information such as the number of customers, customer return rate, transactions and analysis time period. This information can be used to check for outliers or anomalies (e.g. negative prices). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "CTiZxBvrcSeV",
      "metadata": {
        "id": "CTiZxBvrcSeV"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/pierre-emmanuel/Documents/freelance/pltv/venv/lib/python3.9/site-packages/google/cloud/bigquery/table.py:1933: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
            "  warnings.warn(\n",
            "INFO:root:Creating table 'pltv-457408.crystalvalue.crystalvalue_data_statistics' in location 'europe-west9'\n",
            "/Users/pierre-emmanuel/Documents/freelance/pltv/venv/lib/python3.9/site-packages/google/cloud/bigquery/_pandas_helpers.py:489: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "summary_statistics = pipeline.run_data_checks(transaction_table_name=GCP_TABLE_ID_TRAIN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "e4f524c8",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number_of_rows</th>\n",
              "      <th>number_of_customers</th>\n",
              "      <th>number_of_transactions</th>\n",
              "      <th>total_analysis_days</th>\n",
              "      <th>number_of_days_with_data</th>\n",
              "      <th>max_transaction_date</th>\n",
              "      <th>min_transaction_date</th>\n",
              "      <th>lookahead_customer_return_rate</th>\n",
              "      <th>lookahead_customer_mean_returns</th>\n",
              "      <th>lookahead_customer_conditional_mean_returns</th>\n",
              "      <th>value_mean</th>\n",
              "      <th>value_std</th>\n",
              "      <th>value_min</th>\n",
              "      <th>value_25_quantile</th>\n",
              "      <th>value_50_quantile</th>\n",
              "      <th>value_75_quantile</th>\n",
              "      <th>value_max</th>\n",
              "      <th>transactions_per_customer_mean</th>\n",
              "      <th>transactions_per_customer_std</th>\n",
              "      <th>transactions_per_customer_min</th>\n",
              "      <th>transactions_per_customer_25_quantile</th>\n",
              "      <th>transactions_per_customer_50_quantile</th>\n",
              "      <th>transactions_per_customer_75_quantile</th>\n",
              "      <th>transactions_per_customer_max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>statistics</th>\n",
              "      <td>51349</td>\n",
              "      <td>24919</td>\n",
              "      <td>51349</td>\n",
              "      <td>1049</td>\n",
              "      <td>1050</td>\n",
              "      <td>2025-04-15</td>\n",
              "      <td>2022-06-01</td>\n",
              "      <td>0.56</td>\n",
              "      <td>2.43</td>\n",
              "      <td>4.33</td>\n",
              "      <td>49.69</td>\n",
              "      <td>33.12</td>\n",
              "      <td>0.39</td>\n",
              "      <td>39.07</td>\n",
              "      <td>42.57</td>\n",
              "      <td>60.83</td>\n",
              "      <td>2684.79</td>\n",
              "      <td>2.06</td>\n",
              "      <td>2.76</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           number_of_rows number_of_customers number_of_transactions  \\\n",
              "statistics          51349               24919                  51349   \n",
              "\n",
              "           total_analysis_days number_of_days_with_data max_transaction_date  \\\n",
              "statistics                1049                     1050           2025-04-15   \n",
              "\n",
              "           min_transaction_date lookahead_customer_return_rate  \\\n",
              "statistics           2022-06-01                           0.56   \n",
              "\n",
              "           lookahead_customer_mean_returns  \\\n",
              "statistics                            2.43   \n",
              "\n",
              "           lookahead_customer_conditional_mean_returns value_mean value_std  \\\n",
              "statistics                                        4.33      49.69     33.12   \n",
              "\n",
              "           value_min value_25_quantile value_50_quantile value_75_quantile  \\\n",
              "statistics      0.39             39.07             42.57             60.83   \n",
              "\n",
              "           value_max transactions_per_customer_mean  \\\n",
              "statistics   2684.79                           2.06   \n",
              "\n",
              "           transactions_per_customer_std transactions_per_customer_min  \\\n",
              "statistics                          2.76                           1.0   \n",
              "\n",
              "           transactions_per_customer_25_quantile  \\\n",
              "statistics                                   1.0   \n",
              "\n",
              "           transactions_per_customer_50_quantile  \\\n",
              "statistics                                   1.0   \n",
              "\n",
              "           transactions_per_customer_75_quantile transactions_per_customer_max  \n",
              "statistics                                   2.0                          50.0  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "summary_statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afd6f4f0",
      "metadata": {},
      "source": [
        "- `lookahead_customer_return_rate`\n",
        "    - **taux de retour (oui/non)**\n",
        "    - proportion de clients qui ont **au moins une tx future** dans la fenêtre de `days_lookahead`\n",
        "    - mesure de récurrence\n",
        "\n",
        "- `lookahead_customer_mean_returns`\n",
        "    - **jours moyens d’activité future (tous clients)**\n",
        "    - nombre moyen de **jours avec une tx** dans la fenêtre de `lookahead`, par tx\n",
        "    - **combien de jours** sont “actifs” dans la période `lookahead` après chaque tx\n",
        "\n",
        "- `lookahead_customer_conditional_mean_returns`\n",
        "    - **jours moyens d’activité chez ceux qui reviennent**\n",
        "    - moyenne du nombre de jours avec transaction, uniquement chez ceux qui reviennent au moins une fois"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "emCUVYhLFnla",
      "metadata": {
        "id": "emCUVYhLFnla"
      },
      "source": [
        "If a custom data cleaning routine has to be implemented use the `.run_query()` method. The example below removes transactions with negative prices. This method could also be used to run custom feature engineering scripts instead of the automated `.feature_engineering()` method in the next step. This data cleaning routine can be scheduled as part of the pipeline that we will define later (for model training and prediction)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "q_hFsfRGFjxG",
      "metadata": {
        "id": "q_hFsfRGFjxG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "SELECT *\n",
            "FROM pltv-457408.crystalvalue.train\n",
            "WHERE value_cat1 >= 0 AND value_cat2 >= 0 AND value_cat3 >= 0 AND value_cat4 >= 0 AND value_cat5 >= 0 AND value_cat6 >= 0 AND value_uncategorized >= 0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# check if there is any negative value\n",
        "where_clause = [f\"value_cat{i} >= 0\" for i in range(1, 7)]\n",
        "where_clause.append(\"value_uncategorized >= 0\")\n",
        "where_clause = \" AND \".join(where_clause)\n",
        "\n",
        "query = f\"\"\"\n",
        "SELECT *\n",
        "FROM {pipeline.project_id}.{pipeline.dataset_id}.{GCP_TABLE_ID_TRAIN}\n",
        "WHERE {where_clause}\n",
        "\"\"\"\n",
        "\n",
        "print(query)\n",
        "# pipeline.run_query(query_sql=query, destination_table_name=GCP_TABLE_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Bcu6lMlY37w",
      "metadata": {
        "id": "5Bcu6lMlY37w"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Crystalvalue takes a transaction or browsing level dataset and creates a machine learning-ready dataset that can be ingested by AutoML. Data types are automatically inferred from the BigQuery schema unless the features are provided using the `feature_types` parameter in the `.feature_engineer()` method. Data transformations are applied automatically depending on the data type. The data crunching happens in BigQuery and the executed script can be optionally written to your directory. The features will be created in a BigQuery table called `crystalvalue_train_data` by default."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yK5Lfb1SY37w",
      "metadata": {
        "id": "yK5Lfb1SY37w"
      },
      "outputs": [],
      "source": [
        "crystalvalue_train_data = pipeline.feature_engineer(\n",
        "  transaction_table_name=GCP_TABLE_ID_TRAIN,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "xQ0yaFbBY37x",
      "metadata": {
        "id": "xQ0yaFbBY37x"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3JCdyprSY37x",
      "metadata": {
        "id": "3JCdyprSY37x"
      },
      "source": [
        "Crystalvalue leverages [Vertex AI (Tabular) AutoML](https://cloud.google.com/vertex-ai/docs/training/automl-api) which requires a\n",
        "[Vertex AI Dataset](https://cloud.google.com/vertex-ai/docs/datasets/create-dataset-api) as an input. CrystalValue automatically creates a Vertex AI Dataset from your input table as part of the training step of the pipeline. The training process typically takes about 2 or more hours to run. The Vertex AI Dataset will have a display name `crystalvalue_dataset`. The model will have a display name `crystalvalue_model` but it will also receive a model ID (so even if you train multiple models they will not be overwritten and can be identified using these IDs). By default CrystalValue chooses the following parameters:\n",
        "*  Predefined split with random 15% of users as test, 15% in validation and 70% in training.\n",
        "*  Optimization objective as Minimize root-mean-squared error (RMSE).\n",
        "*  1 node hour of training (1000 milli node hours), which we recommend starting with. [Modify this in line with the number of rows](https://cloud.google.com/automl-tables/docs/train#training_a_model) in the dataset when you are ready for productionising. See information here about [pricing](https://cloud.google.com/automl-tables/pricing).\n",
        "\n",
        "In this example we keep all the default settings so training the model is as simple as calling `pipeline.train_automl_model()`.\n",
        "\n",
        "In order to make fast predictions later, you can deploy the model using the `.deploy_model()` method."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "PvryAnPFiuWG",
      "metadata": {
        "id": "PvryAnPFiuWG"
      },
      "source": [
        "Once you start the training, you can view your model training progress here:  \n",
        "https://console.cloud.google.com/vertex-ai/training/training-pipelines  \n",
        "Once the training is finished, check out your Dataset (with statistics and distributions) and Model (with feature importance) in the UI:  \n",
        " https://console.cloud.google.com/vertex-ai/datasets   \n",
        " https://console.cloud.google.com/vertex-ai/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CSK1FtHVY37y",
      "metadata": {
        "id": "CSK1FtHVY37y"
      },
      "outputs": [],
      "source": [
        "model_object = pipeline.train_automl_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dxA48EdTcs3c",
      "metadata": {
        "id": "dxA48EdTcs3c"
      },
      "outputs": [],
      "source": [
        "model_object = pipeline.deploy_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dok2Wu6UY370",
      "metadata": {
        "id": "Dok2Wu6UY370"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wsJdx-MvY370",
      "metadata": {
        "id": "wsJdx-MvY370"
      },
      "source": [
        "To evaluate a model, we use the following criteria:\n",
        "\n",
        "* The spearman correlation, a measure of how well the model **ranked** the Liftetime value of customers in the test set. This is measured between -1 (worse) and 1 (better).\n",
        "* The normalised Gini coefficient, another measure of how well the model **ranked** the Lifetime value of customers in the test set compared to random ranking. This is measured between 0 (worse) and 1 (better). \n",
        "* The normalised Mean Average Error (MAE%). This is a measure of the **error** of the model\"s predictions for Lifetime value in the test set. \n",
        "* top_x_percent_predicted_customer_value_share: The proportion of value (i.e. total profit or revenue) in the test set that is accounted for by the top x% model-predicted customers. \n",
        "\n",
        "These outputs are sent to a BigQuery table (by default called `crystalvalue_evaluation`). Subsequent model evaluations append model performance evaluation metrics to this table to allow for comparison across models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TmTV4LayjXo9",
      "metadata": {
        "id": "TmTV4LayjXo9"
      },
      "outputs": [],
      "source": [
        "metrics = pipeline.evaluate_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oJ6ZFLwrY37y",
      "metadata": {
        "id": "oJ6ZFLwrY37y"
      },
      "source": [
        "# Generating predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jEzDVyiMY37z",
      "metadata": {
        "id": "jEzDVyiMY37z"
      },
      "source": [
        "Once model training is done, you can generate predictions. Features need to be engineered (the exact same as were used for model training) before prediction. This is done using the `.feature_engineer()` method by setting the parameter `query_type=\"predict_query\"`. The features will be created in a BigQuery table called `crystalvalue_predict_data` by default. The model will make predictions for all customers in the provided input table that have any activity during the lookback window. The pLTV predictions will be for the period starting from the last date in the input table (not today\"s date).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z2sOiMID4X2-",
      "metadata": {
        "id": "Z2sOiMID4X2-"
      },
      "outputs": [],
      "source": [
        "crystalvalue_predict_data = pipeline.feature_engineer(\n",
        "    transaction_table_name=GCP_TABLE_ID_PREDICT,  # An existing bigquery table in your dataset id containing the data to predict with.\n",
        "    query_type=\"predict_query\"\n",
        ")\n",
        "\n",
        "\n",
        "predictions = pipeline.predict(\n",
        "    input_table=crystalvalue_predict_data,\n",
        "    destination_table=\"crystalvalue_predictions\"  # The bigquery table to append predictions to. It will be created if it does not exist yet.\n",
        ")  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bDF0AE95vvuv",
      "metadata": {
        "id": "bDF0AE95vvuv"
      },
      "source": [
        "# Scheduling daily predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uWrKLbrEv0xo",
      "metadata": {
        "id": "uWrKLbrEv0xo"
      },
      "source": [
        "Crystalvalue uses [Vertex Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) to schedule and monitor machine learning predictions. It can also be used for model retraining. The example below demonstrates how to set up the model to automatically create predictions using new input data from the source BigQuery table every day at 1am. The frequency and timing of the schedule can be altered using the chron schedule below. Once this pipeline is set up, you can view it [here](https://console.cloud.google.com/vertex-ai/pipelines). If you want a tutorial on how to set up Vertex Pipelines [this guide](https://cloud.google.com/vertex-ai/docs/pipelines/build-pipeline)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZECtoCAyxbxX",
      "metadata": {
        "id": "ZECtoCAyxbxX"
      },
      "source": [
        "In order to use Vertex AI pipelines, we need a cloud storage bucket. Use the code below to create a cloud storage bucket. Note that you may have to grant Storage Object Admin to your service account to ensure the pipeline can run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1zuWtrdwxjKX",
      "metadata": {
        "id": "1zuWtrdwxjKX"
      },
      "outputs": [],
      "source": [
        "BUCKET_NAME = \"crystalvalue_bucket\"\n",
        "storage_bucket = pipeline.create_storage_bucket(bucket_name=BUCKET_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pj3GIIJr5TqC",
      "metadata": {
        "id": "pj3GIIJr5TqC"
      },
      "source": [
        "In order to use Vertex AI pipelines with Crystalvalue we also need to create a docker container which will be stored in Google Cloud Container Registry. The following code builds a docker container and pushes it to your [GCP Container Registry](https://cloud.google.com/container-registry). \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "xCEA0QZo5ale",
      "metadata": {
        "id": "xCEA0QZo5ale"
      },
      "outputs": [],
      "source": [
        "!docker build -t crystalvalue .\n",
        "!docker tag crystalvalue gcr.io/$pipeline.project_id/crystalvalue\n",
        "!docker push gcr.io/$pipeline.project_id/crystalvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JlfrRkrF_jhR",
      "metadata": {
        "id": "JlfrRkrF_jhR"
      },
      "source": [
        "The Kubeflow components contains self-contained functions. Read about [Kubeflow components](https://www.kubeflow.org/docs/components/pipelines/sdk/component-development/).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jT1zxEqGwG17",
      "metadata": {
        "id": "jT1zxEqGwG17"
      },
      "outputs": [],
      "source": [
        "from kfp import dsl\n",
        "from kfp import compiler\n",
        "from kfp.dsl import component\n",
        "\n",
        "\n",
        "@component(base_image=f\"gcr.io/{pipeline.project_id}/crystalvalue:latest\")\n",
        "def pipeline_function():  \n",
        "  from src import crystalvalue\n",
        "  parameters = crystalvalue.load_parameters_from_file()\n",
        "  pipeline = crystalvalue.CrystalValue(**parameters)\n",
        "  TRANSACTION_TABLE = \"online_retail_data\"  # Add your input table name.\n",
        "  pipeline.run_data_checks(transaction_table_name=TRANSACTION_TABLE)  \n",
        "  features = pipeline.feature_engineer(transaction_table_name=TRANSACTION_TABLE,\n",
        "                                       query_type=\"predict_query\")\n",
        "  pipeline.predict(features)\n",
        "\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name=\"crystalvaluepipeline\",\n",
        "    pipeline_root=f\"gs://{BUCKET_NAME}/pipeline_root\",\n",
        ")\n",
        "def crystalvalue_pipeline():\n",
        "    pipeline_function()\n",
        "    \n",
        "compiler.Compiler().compile(\n",
        "  pipeline_func=crystalvalue_pipeline,\n",
        "  package_path=\"crystalvaluepipeline.json\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNSjgatukOKR"
      },
      "outputs": [],
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "# Choose a region compatible with Vertex Pipelines. \n",
        "# This doesn\"t have to be the same as your data location.\n",
        "\n",
        "PROJECT_ID = pipeline.project_id,\n",
        "REGION=pipeline.location,\n",
        "DISPLAY_NAME=\"crystalvalue_pipeline\",\n",
        "PIPELINE_ROOT=f\"gs://{BUCKET_NAME}/pipeline_root\",\n",
        "PACKAGE_PATH=\"crystalvaluepipeline.json\",\n",
        "aiplatform.init(\n",
        "    project=PROJECT_ID,\n",
        "    location=REGION,\n",
        ")\n",
        "\n",
        "pipeline_job = aiplatform.PipelineJob(\n",
        "    display_name=DISPLAY_NAME,\n",
        "    template_path=PACKAGE_PATH,\n",
        "    pipeline_root=PIPELINE_ROOT,\n",
        ")\n",
        "\n",
        "## Check if your pipeline is running.\n",
        "job.submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e_uER_PJ_fNW",
      "metadata": {
        "id": "e_uER_PJ_fNW"
      },
      "source": [
        "Create the scheduled pipeline. Adjust time zone and cron schedule as necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7L0QRKOaLYM"
      },
      "outputs": [],
      "source": [
        "pipeline_job_schedule = pipeline_job.create_schedule(\n",
        "  display_name=\"crystalvalue_pipeline_schedule\",\n",
        "  cron=\"TZ=CRON\",\n",
        "  max_concurrent_run_count=MAX_CONCURRENT_RUN_COUNT,\n",
        "  max_run_count=MAX_RUN_COUNT,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sxeSm7BxA5so",
      "metadata": {
        "id": "sxeSm7BxA5so"
      },
      "source": [
        "You can view your running and scheduled pipelines at:\n",
        "https://console.cloud.google.com/vertex-ai/pipelines or by adjusting the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac4RlBqXaLYM"
      },
      "outputs": [],
      "source": [
        "aiplatform.PipelineJobSchedule.list(\n",
        "  filter=\"display_name=\"DISPLAY_NAME\"\",\n",
        "  order_by=\"create_time desc\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "yNZpQxNU-cIi",
      "metadata": {
        "id": "yNZpQxNU-cIi"
      },
      "source": [
        "# (Optional) Get insights into the relationship between your features and customer LTV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZXZUlaZV_Ms9",
      "metadata": {
        "id": "ZXZUlaZV_Ms9"
      },
      "source": [
        "To get insights into how your model is making predictions based on your features using the [What-If Tool](https://pair-code.github.io/what-if-tool/). Check out an [online demo here](https://pair-code.github.io/what-if-tool/demos/age.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0HyVMxQj-jfl",
      "metadata": {
        "id": "0HyVMxQj-jfl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from witwidget.notebook.visualization import WitConfigBuilder\n",
        "from witwidget.notebook.visualization import WitWidget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CUK1kcr0-pS7",
      "metadata": {
        "id": "CUK1kcr0-pS7"
      },
      "outputs": [],
      "source": [
        "features_with_predictions = pd.concat([\n",
        "    crystalvalue_predict_data.iloc[:,7:],\n",
        "    predictions[\"predicted_value\"]], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "s8hedfxF-qcn",
      "metadata": {
        "id": "s8hedfxF-qcn"
      },
      "outputs": [],
      "source": [
        "config_builder = WitConfigBuilder(\n",
        "    np.array(features_with_predictions[0:1000]).tolist(),\n",
        "    list(features_with_predictions)\n",
        ")\n",
        "WitWidget(config_builder, height=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "R7RczTD6S1_O",
      "metadata": {
        "id": "R7RczTD6S1_O"
      },
      "source": [
        "# Clean Up"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6FyiJ93rTWhW",
      "metadata": {
        "id": "6FyiJ93rTWhW"
      },
      "source": [
        "To clean up tables created during this demo, delete the BigQuery tables that were created. All Vertex AI resources can be removed from the [Vertex AI console](https://console.cloud.google.com/vertex-ai). If you set up a Vertex Pipeline then also remove any relevant resources from [Cloud Storage](https://console.cloud.google.com/storage) and [Container Registry](https://console.cloud.google.com//gcr/images/). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1wQI6E8US3Hc",
      "metadata": {
        "id": "1wQI6E8US3Hc"
      },
      "outputs": [],
      "source": [
        "pipeline.delete_table(\"crystalvalue_data_statistics\")\n",
        "pipeline.delete_table(\"crystalvalue_evaluation\")\n",
        "pipeline.delete_table(\"crystalvalue_train_data\")\n",
        "pipeline.delete_table(\"crystalvalue_predict_data\")\n",
        "pipeline.delete_table(\"crystalvalue_predictions\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "last_runtime": {
        "build_target": "//corp/gtech/ads/infrastructure/colab_utils/ds_runtime:ds_colab",
        "kind": "private"
      },
      "name": "demo_with_real_data_notebook.ipynb",
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/crystalvalue/crystalvalue_demo_notebook.ipynb?workspaceId=sumedhamenon:CrystalValue::citc",
          "timestamp": 1627656627042
        },
        {
          "file_id": "/piper/depot/google3/third_party/professional_services/solutions/crystalvalue/crystalvalue_demo_notebook.ipynb?workspaceId=sumedhamenon:CrystalValue::citc",
          "timestamp": 1627656460877
        },
        {
          "file_id": "/piper/depot/google3/experimental/gtech_prem_data_science/projects/trac/treatwell/Crystal_Value_Demo_Notebook.ipynb?workspaceId=sumedhamenon:CrystalValue::citc",
          "timestamp": 1627648785641
        },
        {
          "file_id": "1JGQRDc1_luQsaMxx9ZZavddHBrgO7Xst",
          "timestamp": 1627648471137
        }
      ]
    },
    "environment": {
      "name": "common-cpu.mnightly-2021-01-05-debian-10-test",
      "type": "gcloud",
      "uri": "gcr.io/deeplearning-platform-release/base-cpu:mnightly-2021-01-05-debian-10-test"
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
